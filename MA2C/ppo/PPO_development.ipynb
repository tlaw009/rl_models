{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a054ac7",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "id": "e3907038",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import gym\n",
    "import scipy.signal\n",
    "import time\n",
    "from tensorflow.keras import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a67588e",
   "metadata": {},
   "source": [
    "### Env Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "id": "fb9f396c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "problem = \"Hopper-v3\"\n",
    "env = gym.make(problem)\n",
    "\n",
    "num_states = env.observation_space.shape[0]\n",
    "num_actions = env.action_space.shape[0]\n",
    "upper_bound = env.action_space.high[0]\n",
    "lower_bound = env.action_space.low[0]\n",
    "\n",
    "num_states, num_states, upper_bound, lower_bound\n",
    "\n",
    "EPSILON = 1e-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fae4cbb",
   "metadata": {},
   "source": [
    "### Actor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1135,
   "id": "171173d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(Model):\n",
    "\n",
    "    def __init__(self, action_dimensions):\n",
    "        super().__init__()\n",
    "        self.action_dim = action_dimensions\n",
    "        self.sample_dist = tfp.distributions.MultivariateNormalDiag(loc=tf.zeros(num_actions),\n",
    "                                                                    scale_diag=tf.ones(num_actions))\n",
    "        self.dense1_layer = layers.Dense(256, activation=\"relu\")\n",
    "        self.dense2_layer = layers.Dense(256, activation=\"relu\")\n",
    "        self.mean_layer = layers.Dense(self.action_dim)\n",
    "        self.stdev_layer = layers.Dense(self.action_dim)\n",
    "\n",
    "    def call(self, state, eval_mode=False):\n",
    "\n",
    "        a1 = self.dense1_layer(state)\n",
    "        a2 = self.dense2_layer(a1)\n",
    "        mu = self.mean_layer(a2)\n",
    "\n",
    "        log_sigma = self.stdev_layer(a2)\n",
    "        sigma = tf.exp(log_sigma)\n",
    "\n",
    "        dist = tfp.distributions.MultivariateNormalDiag(loc=mu, scale_diag=sigma)\n",
    "\n",
    "        if eval_mode:\n",
    "            action_ = mu\n",
    "        else:\n",
    "            action_ = tf.math.add(mu, tf.math.multiply(sigma, tf.expand_dims(self.sample_dist.sample(), 0)))\n",
    " \n",
    "        action = tf.tanh(action_)\n",
    "\n",
    "        log_pi_ = dist.log_prob(action_)     \n",
    "        log_pi = log_pi_ - tf.reduce_sum(tf.math.log(tf.clip_by_value(1 - action**2, EPSILON, 1.0)), axis=1)\n",
    "        \n",
    "        print(sigma)\n",
    "        s_e = tf.expand_dims(self.sample_dist.sample(), 0)\n",
    "        print(\"Sample epsilon: \", s_e)\n",
    "        print(tf.math.multiply(sigma, s_e))\n",
    "        return action*upper_bound, log_pi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cfef03",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "id": "272f8fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_test = Actor(num_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "id": "98cbd43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1.1533982  0.9330433  0.95782125]], shape=(1, 3), dtype=float32)\n",
      "Sample epsilon:  tf.Tensor([[ 0.19212519 -0.32455724  0.6135523 ]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([[ 0.22159684 -0.30282596  0.5876734 ]], shape=(1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "obs\n",
    "tf_obs = tf.expand_dims(obs, 0)\n",
    "tf_obs\n",
    "a_test, log_a_test = actor_test(tf_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "id": "d3695861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1.1533982  0.9330433  0.95782125]]\n",
      "\n",
      " [[1.0369197  0.9678792  0.916226  ]]], shape=(2, 1, 3), dtype=float32)\n",
      "Sample epsilon:  tf.Tensor([[ 0.00502631  0.7337843  -0.04475469]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[ 0.00579733  0.68465257 -0.04286699]]\n",
      "\n",
      " [[ 0.00521188  0.71021456 -0.04100541]]], shape=(2, 1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "obs_new, _, _, _ = env.step(a_test[0])\n",
    "tf_obs_new = tf.expand_dims(obs_new, 0)\n",
    "a_test, log_a_test = actor_test(tf.convert_to_tensor([tf_obs, tf_obs_new]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "id": "f5f078df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"actor_158\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1126 (Dense)          multiple                  3072      \n",
      "                                                                 \n",
      " dense_1127 (Dense)          multiple                  65792     \n",
      "                                                                 \n",
      " dense_1128 (Dense)          multiple                  771       \n",
      "                                                                 \n",
      " dense_1129 (Dense)          multiple                  771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,406\n",
      "Trainable params: 70,406\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "actor_test.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1455d2c3",
   "metadata": {},
   "source": [
    "### Critic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "id": "5abf1439",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic_Wrapper():\n",
    "    def __init__(self, state_dim):\n",
    "        self.s_dim=state_dim\n",
    "        \n",
    "    def get_critic(self):\n",
    "        # State as input\n",
    "        state_input = layers.Input(shape=(self.s_dim))\n",
    "        state_out = layers.Dense(256, activation=\"relu\")(state_input)\n",
    "        # state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
    "\n",
    "        out = layers.Dense(256, activation=\"relu\")(state_out)\n",
    "        outputs = layers.Dense(1, dtype='float64')(out)\n",
    "\n",
    "        # Outputs single value for give state-action\n",
    "        model = tf.keras.Model([state_input], outputs)\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78818afa",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "id": "62e54cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_gen = Critic_Wrapper(num_states)\n",
    "critic_test = critic_gen.get_critic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "id": "b225743f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.25271482e+00,  2.79971789e-03, -1.63619178e-03, -1.33913395e-03,\n",
       "        1.33965093e-03, -3.43120515e-03,  6.74936643e-04,  4.76680213e-03,\n",
       "       -4.15028315e-03,  6.28646674e-04, -4.57904844e-03])"
      ]
     },
     "execution_count": 1097,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "id": "10c567b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 11), dtype=float64, numpy=\n",
       "array([[ 1.25271482e+00,  2.79971789e-03, -1.63619178e-03,\n",
       "        -1.33913395e-03,  1.33965093e-03, -3.43120515e-03,\n",
       "         6.74936643e-04,  4.76680213e-03, -4.15028315e-03,\n",
       "         6.28646674e-04, -4.57904844e-03]])>"
      ]
     },
     "execution_count": 1098,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_obs = tf.expand_dims(obs, 0)\n",
    "a_test, log_a_test = actor_test(tf_obs)\n",
    "tf_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "id": "a31d1e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.036233229949890575>"
      ]
     },
     "execution_count": 1099,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_test = tf.squeeze(critic_test([tf_obs]))\n",
    "v_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "id": "f30c2bfb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_150\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_193 (InputLayer)      [(None, 11)]              0         \n",
      "                                                                 \n",
      " dense_1130 (Dense)          (None, 256)               3072      \n",
      "                                                                 \n",
      " dense_1131 (Dense)          (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_1132 (Dense)          (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,121\n",
      "Trainable params: 69,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "critic_test.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fdffc8",
   "metadata": {},
   "source": [
    "### Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "id": "dde6162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer:\n",
    "\n",
    "    def __init__(self, observation_dimensions, action_dimensions, size, minibatch_size=256, gamma=0.99, lam=0.95):\n",
    "\n",
    "        self.observation_buffer = np.zeros(\n",
    "            (size, observation_dimensions), dtype=np.float32\n",
    "        )\n",
    "        self.action_buffer = np.zeros((size, action_dimensions), dtype=np.float32)\n",
    "        self.reward_buffer = np.zeros(size, dtype=np.float32)\n",
    "        self.logprobability_buffer = np.zeros(size, dtype=np.float32)\n",
    "        \n",
    "        self.gamma, self.lam = gamma, lam\n",
    "        self.batch_size = minibatch_size\n",
    "        \n",
    "        self.buffer_cap = size\n",
    "        self.pointer = 0\n",
    "        self.trajectory_start_indices = []\n",
    "        self.trajectory_start_indices.append(0)\n",
    "\n",
    "    def store(self, observation, action, reward, logprobability, done):\n",
    "\n",
    "        self.observation_buffer[self.pointer] = observation\n",
    "        self.action_buffer[self.pointer] = action\n",
    "        self.reward_buffer[self.pointer] = reward\n",
    "        self.logprobability_buffer[self.pointer] = logprobability\n",
    "        self.pointer += 1\n",
    "        if done and not self.pointer > self.buffer_cap-1:\n",
    "            self.trajectory_start_indices.append(self.pointer)\n",
    "\n",
    "\n",
    "    def get(self):\n",
    "        # Get all data of the buffer\n",
    "        if self.trajectory_start_indices[-1] == self.buffer_cap-1:\n",
    "            rindex = np.random.choice(range(len(self.trajectory_start_indices)-1), self.batch_size)\n",
    "        else:\n",
    "            rindex = np.random.choice(range(len(self.trajectory_start_indices)), self.batch_size)\n",
    "        \n",
    "        isolated_obs=[]\n",
    "        isolated_a=[]\n",
    "        isolated_r=[]\n",
    "        isolated_log_a=[]\n",
    "        for ri in rindex:\n",
    "            \n",
    "            if  ri == len(self.trajectory_start_indices)-1:\n",
    "                isolated_obs.append(self.observation_buffer[self.trajectory_start_indices[ri]:\n",
    "                                                       self.buffer_cap])\n",
    "                isolated_a.append(self.action_buffer[self.trajectory_start_indices[ri]:\n",
    "                                                       self.buffer_cap])\n",
    "                isolated_r.append(self.reward_buffer[self.trajectory_start_indices[ri]:\n",
    "                                                       self.buffer_cap])\n",
    "                isolated_log_a.append(self.logprobability_buffer[self.trajectory_start_indices[ri]:\n",
    "                                                       self.buffer_cap])\n",
    "                \n",
    "            else:\n",
    "                isolated_obs.append(self.observation_buffer[self.trajectory_start_indices[ri]:\n",
    "                                                       self.trajectory_start_indices[ri+1]])\n",
    "                isolated_a.append(self.action_buffer[self.trajectory_start_indices[ri]:\n",
    "                                                       self.trajectory_start_indices[ri+1]])\n",
    "                isolated_r.append(self.reward_buffer[self.trajectory_start_indices[ri]:\n",
    "                                                       self.trajectory_start_indices[ri+1]])\n",
    "                isolated_log_a.append(self.logprobability_buffer[self.trajectory_start_indices[ri]:\n",
    "                                                       self.trajectory_start_indices[ri+1]])\n",
    "\n",
    "        return (\n",
    "            isolated_obs,\n",
    "            isolated_a,\n",
    "            isolated_r,\n",
    "            isolated_log_a,\n",
    "        )\n",
    "    \n",
    "    def batch_sample(self, critic_handle):\n",
    "        s_b, a_b, r_b, l_b = self.get()\n",
    "        ss_b = []\n",
    "        as_b = []\n",
    "        rs_b = []\n",
    "        ls_b = []\n",
    "        adv_b = []\n",
    "        ret_b = []\n",
    "        sample_idxs = [np.random.choice(range(len(a)-1)) for a in s_b]\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            ss_b.append(s_b[i][sample_idxs[i]])\n",
    "            as_b.append(a_b[i][sample_idxs[i]])\n",
    "            rs_b.append(r_b[i][sample_idxs[i]])\n",
    "            ls_b.append(l_b[i][sample_idxs[i]])\n",
    "            adv_b.append(self.adv_t(r_b[i][sample_idxs[i]:-1],\n",
    "                                      critic_handle,\n",
    "                                      s_b[i][sample_idxs[i]:-1],\n",
    "                                      s_b[i][sample_idxs[i]+1:]))\n",
    "            ret_b.append(self.ret_t(r_b[i][sample_idxs[i]:]))\n",
    "        return (\n",
    "            tf.convert_to_tensor(ss_b),\n",
    "            tf.convert_to_tensor(as_b),\n",
    "            tf.convert_to_tensor(adv_b),\n",
    "            tf.convert_to_tensor(ret_b),\n",
    "            tf.convert_to_tensor(ls_b),\n",
    "            tf.convert_to_tensor(rs_b)\n",
    "        )\n",
    "        \n",
    "    def adv_t(self, r_t, vf, s_t, s_t1):\n",
    "        ite_gamma_lam = [(self.gamma*self.lam)**i for i in range(len(r_t))]\n",
    "        delta_ts = r_t + self.gamma*tf.squeeze(vf(s_t1)) - tf.squeeze(vf(s_t))\n",
    "\n",
    "        return np.sum(np.multiply(ite_gamma_lam, delta_ts))\n",
    "    \n",
    "    def ret_t(self, r_t):\n",
    "        ite_gamma = [self.gamma**i for i in range(len(r_t))]\n",
    "        \n",
    "        return np.sum(np.multiply(ite_gamma, r_t))\n",
    "    \n",
    "    def clear(self):\n",
    "        self.pointer = 0\n",
    "        self.trajectory_start_indices = []\n",
    "        self.trajectory_start_indices.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b83ec82",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "id": "5bfa0b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = Buffer(num_states, num_actions, 100, 5)\n",
    "actor_test = Actor(num_actions)\n",
    "critic_gen = Critic_Wrapper(num_states)\n",
    "critic_test = critic_gen.get_critic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "id": "37ade060",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 12, 23, 40, 57, 70, 87]\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "buffer.clear()\n",
    "for x in range(100):\n",
    "    tf_obs = tf.expand_dims(obs, 0)\n",
    "    a, log_a = actor_test(tf_obs)\n",
    "    a = a[0]\n",
    "    obs_new, r, d, _ = env.step(a)\n",
    "    \n",
    "    buffer.store(obs, a, r, log_a, d)\n",
    "    if d:\n",
    "        obs = env.reset()\n",
    "    else:\n",
    "        obs = obs_new\n",
    "    \n",
    "print(buffer.trajectory_start_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "id": "aedab51d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s_b, a_b, r_b, l_b = buffer.get()\n",
    "# np.array(s_b, dtype=object).shape, np.array(a_b, dtype=object).shape, np.array(r_b, dtype=object).shape, np.array(l_b, dtype=object).shape\n",
    "# np.array(s_b, dtype=object), np.array(a_b, dtype=object), np.array(r_b, dtype=object), np.array(l_b, dtype=object)\n",
    "# print(\"trajectory len: \", len(s_b[0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "id": "5c1bc4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(5, 11), dtype=float32, numpy=\n",
       " array([[ 1.2255454e+00, -2.8130250e-02, -1.5443403e-02, -3.3060860e-02,\n",
       "         -1.8586377e-02, -1.5734534e-01, -7.4212414e-01, -2.3261580e+00,\n",
       "         -2.4034238e+00, -7.5640047e-01,  2.0821412e+00],\n",
       "        [ 1.2080775e+00, -7.9052143e-02, -2.7084652e-02, -1.2352135e-01,\n",
       "          1.8645383e-01, -8.8629521e-02, -2.2985950e-01, -3.6071446e+00,\n",
       "         -2.9314358e+00, -2.6402762e+00,  2.1169651e+00],\n",
       "        [ 1.2152959e+00, -1.2636462e-01, -1.9897884e-02, -2.3831084e-01,\n",
       "          4.9185038e-02, -8.2101423e-01, -8.2815582e-01, -5.2101607e+00,\n",
       "         -2.7035944e+00, -5.4663806e+00,  2.3161933e+00],\n",
       "        [ 1.2222453e+00, -1.4662923e-01, -1.2887014e-01, -8.5827507e-02,\n",
       "          2.5990418e-01, -2.5638029e-01, -5.7340896e-01, -4.1354628e+00,\n",
       "         -2.9734170e+00, -4.0964475e+00,  7.6045208e+00],\n",
       "        [ 1.2417740e+00,  1.4921312e-03,  5.0133835e-03, -2.1059953e-02,\n",
       "          7.2312012e-02, -8.7250061e-02, -3.9589050e-01, -7.9022014e-01,\n",
       "         -1.1059048e-03, -1.9919621e+00,  4.8979468e+00]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
       " array([[ 0.87124115,  0.17325957,  0.7201335 ],\n",
       "        [-0.42881778, -0.03897617,  0.01251602],\n",
       "        [-0.82893074, -0.7019942 ,  0.8466312 ],\n",
       "        [-0.9952171 ,  0.14446709,  0.56708026],\n",
       "        [-0.6610836 ,  0.12666304, -0.87744945]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5,), dtype=float64, numpy=array([4.58699412, 1.81534602, 0.2174565 , 0.67268563, 4.32620269])>,\n",
       " <tf.Tensor: shape=(5,), dtype=float64, numpy=array([5.4078059 , 2.50018069, 0.01533423, 1.57638229, 4.80931198])>,\n",
       " <tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       " array([-2.088605 , -4.247674 , -1.4406216, -0.5581713, -3.2106733],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       " array([0.8903204 , 0.9077242 , 0.08785649, 0.7630858 , 0.88691276],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 1105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer.batch_sample(critic_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0e9f65",
   "metadata": {},
   "source": [
    "### PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "id": "a2f7fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO:\n",
    "    \n",
    "    def __init__(self, env, observation_dimensions, action_dimensions, horizon,\n",
    "                 minibatch_size=256, gamma=0.99, lam=0.95, diagnostic_length=1, lr=3e-4):\n",
    "        \n",
    "        self.env = env\n",
    "        self.actor = Actor(action_dimensions)\n",
    "        self.critic_gen = Critic_Wrapper(observation_dimensions)\n",
    "        self.critic = self.critic_gen.get_critic()\n",
    "        self.buffer = Buffer(observation_dimensions, action_dimensions, horizon, minibatch_size, gamma, lam)\n",
    "        \n",
    "        self.p_opt= tf.keras.optimizers.Adam(learning_rate=lr,\n",
    "                                                            )\n",
    "        self.v_opt= tf.keras.optimizers.Adam(learning_rate=lr,\n",
    "                                                            )\n",
    "        self.clip_epsilon = 0.2\n",
    "        \n",
    "        self.diagnostics_buffer = []\n",
    "        self.diagno_index = 0\n",
    "        self.diagno_length = diagnostic_length\n",
    "        \n",
    "        self.gamma, self.lam, self.horizon = gamma, lam, horizon\n",
    "        \n",
    "    def train(self, iterations, epochs=20):\n",
    "        \n",
    "        for i in range(iterations):\n",
    "            \n",
    "            obs = self.env.reset()\n",
    "            \n",
    "            for t in range(self.horizon):\n",
    "                \n",
    "                tf_obs = tf.expand_dims(obs, 0)\n",
    "                a, log_a = self.actor(tf_obs)\n",
    "                a=a[0]\n",
    "            \n",
    "                obs_new, r, d, _ = self.env.step(a)\n",
    "                \n",
    "                self.buffer.store(obs, a, r, log_a, d)\n",
    "                \n",
    "                if d:\n",
    "                    obs = self.env.reset()\n",
    "                else:\n",
    "                    obs = obs_new\n",
    "\n",
    "            for _ in range(epochs):\n",
    "                (\n",
    "                    obs_b,\n",
    "                    a_b,\n",
    "                    adv_b,\n",
    "                    ret_b,\n",
    "                    log_b,\n",
    "                    r_b,\n",
    "                ) = self.buffer.batch_sample(self.critic)\n",
    "                self.update(obs_b, adv_b, log_b, ret_b)\n",
    "            self.show_diagnostics()    \n",
    "            self.buffer.clear()\n",
    "            \n",
    "    def update(self, obs_b, adv_b, log_b, ret_b):\n",
    "        with tf.GradientTape() as tape:\n",
    "            a, log_a = self.actor(obs_b)\n",
    "            ratio = tf.exp(log_a - log_b)\n",
    "            c_ratio = tf.clip_by_value(ratio, 1.0-self.clip_epsilon, 1.0+self.clip_epsilon)\n",
    "\n",
    "            rt_at = tf.minimum(tf.math.multiply(ratio, tf.cast(adv_b, tf.float32)), \n",
    "                               tf.math.multiply(c_ratio, tf.cast(adv_b, tf.float32)))\n",
    "\n",
    "            L_theta_clip = -tf.reduce_mean(rt_at)\n",
    "        J_theta_clip = tape.gradient(L_theta_clip, self.actor.trainable_variables)\n",
    "        self.p_opt.apply_gradients(zip(J_theta_clip, self.actor.trainable_variables))\n",
    "        \n",
    "        with tf.GradientTape() as tape1:\n",
    "            v_theta = tf.squeeze(self.critic(obs_b))\n",
    "            v_mse = tf.reduce_mean((v_theta - ret_b)**2)\n",
    "        J_phi = tape1.gradient(v_mse, self.critic.trainable_variables)\n",
    "        self.v_opt.apply_gradients(zip(J_phi, self.critic.trainable_variables))\n",
    "        self.record_diagnostics([\"policy loss: \", np.array(L_theta_clip), \"value loss: \", np.array(v_mse)])\n",
    "        \n",
    "    def record_diagnostics(self, data):\n",
    "        if len(self.diagnostics_buffer) == self.diagno_length:\n",
    "            self.diagnostics_buffer[self.diagno_index] = data\n",
    "\n",
    "        if len(self.diagnostics_buffer) < self.diagno_length:\n",
    "            self.diagnostics_buffer.append(data)\n",
    "        self.diagno_index = (self.diagno_index+1)%self.diagno_length\n",
    "    def show_diagnostics(self):\n",
    "        for i in range(len(self.diagnostics_buffer)):\n",
    "            print(self.diagnostics_buffer[(self.diagno_index+i)%len(self.diagnostics_buffer)])\n",
    "            \n",
    "    def save_weights(self, a_path, c_path):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def load_weights(self, a_path, c_path):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e663a9",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "id": "07ed912c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['policy loss: ', array(-0.95306444, dtype=float32), 'value loss: ', array(20.21711021)]\n",
      "['policy loss: ', array(-0.62134653, dtype=float32), 'value loss: ', array(56.98488945)]\n",
      "['policy loss: ', array(-0.6764257, dtype=float32), 'value loss: ', array(34.49099413)]\n",
      "['policy loss: ', array(-0.46545815, dtype=float32), 'value loss: ', array(15.88138123)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1107]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m ppo1 \u001b[38;5;241m=\u001b[39m PPO(env, num_states, num_actions, \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mppo1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [1106]\u001b[0m, in \u001b[0;36mPPO.train\u001b[0;34m(self, iterations, epochs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         obs \u001b[38;5;241m=\u001b[39m obs_new\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     46\u001b[0m     (\n\u001b[1;32m     47\u001b[0m         obs_b,\n\u001b[1;32m     48\u001b[0m         a_b,\n\u001b[1;32m     49\u001b[0m         adv_b,\n\u001b[1;32m     50\u001b[0m         ret_b,\n\u001b[1;32m     51\u001b[0m         log_b,\n\u001b[1;32m     52\u001b[0m         r_b,\n\u001b[0;32m---> 53\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcritic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(obs_b, adv_b, log_b, ret_b)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_diagnostics()    \n",
      "Input \u001b[0;32mIn [1101]\u001b[0m, in \u001b[0;36mBuffer.batch_sample\u001b[0;34m(self, critic_handle)\u001b[0m\n\u001b[1;32m     84\u001b[0m     rs_b\u001b[38;5;241m.\u001b[39mappend(r_b[i][sample_idxs[i]])\n\u001b[1;32m     85\u001b[0m     ls_b\u001b[38;5;241m.\u001b[39mappend(l_b[i][sample_idxs[i]])\n\u001b[0;32m---> 86\u001b[0m     adv_b\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madv_t\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr_b\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_idxs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mcritic_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m                              \u001b[49m\u001b[43ms_b\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_idxs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m                              \u001b[49m\u001b[43ms_b\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_idxs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     90\u001b[0m     ret_b\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mret_t(r_b[i][sample_idxs[i]:]))\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     92\u001b[0m     tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(ss_b),\n\u001b[1;32m     93\u001b[0m     tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(as_b),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m     tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(rs_b)\n\u001b[1;32m     98\u001b[0m )\n",
      "Input \u001b[0;32mIn [1101]\u001b[0m, in \u001b[0;36mBuffer.adv_t\u001b[0;34m(self, r_t, vf, s_t, s_t1)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madv_t\u001b[39m(\u001b[38;5;28mself\u001b[39m, r_t, vf, s_t, s_t1):\n\u001b[1;32m    101\u001b[0m     ite_gamma_lam \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlam)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mi \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(r_t))]\n\u001b[0;32m--> 102\u001b[0m     delta_ts \u001b[38;5;241m=\u001b[39m r_t \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvf\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms_t1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m tf\u001b[38;5;241m.\u001b[39msqueeze(vf(s_t))\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mmultiply(ite_gamma_lam, delta_ts))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ppo1 = PPO(env, num_states, num_actions, 1000)\n",
    "ppo1.train(1000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd6e26a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e55990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
